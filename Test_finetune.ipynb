{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改当前路径为你的数据目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_src = 'D:\\DogsVsCats_finetune'#修改到你的数据文件夹目录\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "#转换目录\n",
    "os.chdir(root_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义生成文件夹函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_directory(dir_name):\n",
    "    if os.path.exists(dir_name):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据train文件夹中的图像数据，以2:8比例分别放入validation、train2文件夹，便于用图片生成器生成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random as rd\n",
    "train_valid_split_rate = 0.2\n",
    "#创建训练数据所需的文件夹\n",
    "create_directory('train2')\n",
    "create_directory('train2/cat')\n",
    "create_directory('train2/dog')\n",
    "create_directory('validation')\n",
    "create_directory('validation/cat')\n",
    "create_directory('validation/dog')\n",
    "#获取当前狗和猫图片的文件名\n",
    "filenames = os.listdir('train')\n",
    "cat_filenames = list(filter(lambda x:x[:3] == 'cat', filenames))\n",
    "cat_file_num = len(cat_filenames)\n",
    "rd.shuffle(cat_filenames)\n",
    "dog_filenames = list(filter(lambda x:x[:3] == 'dog', filenames))\n",
    "dog_file_num = len(dog_filenames)\n",
    "rd.shuffle(dog_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path deal time is 0.01651 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#将cat类和dog类图片归类到train2、validation文件夹\n",
    "for name in tqdm(cat_filenames[0:int(train_valid_split_rate*cat_file_num)]):\n",
    "    shutil.move('./train/'+name, './validation/cat/'+name)\n",
    "for name in tqdm(dog_filenames[0:int(train_valid_split_rate*dog_file_num)]):\n",
    "    shutil.move('./train/'+name, './validation/dog/'+name)\n",
    "\n",
    "for name in tqdm(cat_filenames[int(train_valid_split_rate*cat_file_num):cat_file_num]):\n",
    "    shutil.move('./train/'+name, './train2/cat/'+name)\n",
    "for name in tqdm(dog_filenames[int(train_valid_split_rate*cat_file_num):dog_file_num]):\n",
    "    shutil.move('./train/'+name, './train2/dog/'+name)\n",
    "\n",
    "end = time.time()\n",
    "print('path deal time is %.5f s'%round(end-start,5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理test文件夹，便于用图片生成器生成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path deal time is 0.28306 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "filenames = os.listdir('test')\n",
    "create_directory('test/test2')\n",
    "if len(filenames) <= 1:\n",
    "    pass\n",
    "else:\n",
    "    for name in tqdm(filenames):\n",
    "        shutil.move('test/'+name,'test/test2'+'/'+name)\n",
    "    else:\n",
    "        pass\n",
    "end = time.time()\n",
    "print('path deal time is %.5f s'%round(end-start,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import *\n",
    "import numpy as np\n",
    "BatchSize = 64\n",
    "train_file_num = 25000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置早停函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入InceptionV3、ResNet50、Xception的imagenet模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model1 = InceptionV3(weights='imagenet', include_top=False)\n",
    "base_model2 = ResNet50(weights='imagenet', include_top=False)\n",
    "base_model3 = Xception(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n",
      "174\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "print(len(base_model1.layers))\n",
    "print(len(base_model2.layers))\n",
    "print(len(base_model3.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "Img_enerator = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = Img_enerator.flow_from_directory(\n",
    "        'train2',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BatchSize,\n",
    "        class_mode='binary')\n",
    "validation_generator = Img_enerator.flow_from_directory(\n",
    "        'validation',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BatchSize,\n",
    "        class_mode='binary')\n",
    "test_generator = Img_enerator.flow_from_directory(\n",
    "        'test',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BatchSize,\n",
    "        class_mode='binary',\n",
    "        shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 选择InceptionV3搭建基准模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基准模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: g Pages: 1 -->\r\n",
       "<svg width=\"238pt\" height=\"433pt\"\r\n",
       " viewBox=\"0.00 0.00 238.00 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\r\n",
       "<title>g</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-429 234,-429 234,4 -4,4\"/>\r\n",
       "<!-- node0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>node0</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"88,-401.5 88,-424.5 142,-424.5 142,-401.5 88,-401.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"115\" y=\"-409.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">image</text>\r\n",
       "</g>\r\n",
       "<!-- node1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>node1</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-318.5 0,-364.5 230,-364.5 230,-318.5 0,-318.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"43\" y=\"-337.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">InceptionV3</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"86,-318.5 86,-364.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"114\" y=\"-349.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"86,-341.5 142,-341.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"114\" y=\"-326.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"142,-318.5 142,-364.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-349.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(299, 299, 3)</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"142,-341.5 230,-341.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-326.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(2048)</text>\r\n",
       "</g>\r\n",
       "<!-- node0&#45;&gt;node1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>node0&#45;&gt;node1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M115,-401.444C115,-394.305 115,-384.462 115,-374.862\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.5,-374.681 115,-364.681 111.5,-374.681 118.5,-374.681\"/>\r\n",
       "</g>\r\n",
       "<!-- node2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>node2</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"26.5,-212.5 26.5,-281.5 203.5,-281.5 203.5,-212.5 26.5,-212.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"52\" y=\"-243.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dense</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"77.5,-212.5 77.5,-281.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"114\" y=\"-266.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">activation:</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"77.5,-258.5 150.5,-258.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"114\" y=\"-243.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"77.5,-235.5 150.5,-235.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"114\" y=\"-220.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"150.5,-212.5 150.5,-281.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-266.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"150.5,-258.5 203.5,-258.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-243.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(2048)</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"150.5,-235.5 203.5,-235.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-220.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(256)</text>\r\n",
       "</g>\r\n",
       "<!-- node1&#45;&gt;node2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>node1&#45;&gt;node2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M115,-318.108C115,-310.183 115,-300.971 115,-291.882\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.5,-291.746 115,-281.746 111.5,-291.746 118.5,-291.746\"/>\r\n",
       "</g>\r\n",
       "<!-- node3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>node3</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"14,-106.5 14,-175.5 216,-175.5 216,-106.5 14,-106.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-137.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dropout</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"78,-106.5 78,-175.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-160.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dropout_rate:</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"78,-152.5 170,-152.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-137.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"78,-129.5 170,-129.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-114.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"170,-106.5 170,-175.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-160.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.2</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"170,-152.5 216,-152.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-137.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(256)</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"170,-129.5 216,-129.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-114.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(256)</text>\r\n",
       "</g>\r\n",
       "<!-- node2&#45;&gt;node3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>node2&#45;&gt;node3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M115,-212.234C115,-203.793 115,-194.619 115,-185.77\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.5,-185.596 115,-175.596 111.5,-185.596 118.5,-185.596\"/>\r\n",
       "</g>\r\n",
       "<!-- node4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>node4</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"22.5,-0.5 22.5,-69.5 207.5,-69.5 207.5,-0.5 22.5,-0.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"48\" y=\"-31.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Dense</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"73.5,-0.5 73.5,-69.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"110\" y=\"-54.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">activation:</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"73.5,-46.5 146.5,-46.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"110\" y=\"-31.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"73.5,-23.5 146.5,-23.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"110\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"146.5,-0.5 146.5,-69.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-54.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sigmoid</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"146.5,-46.5 207.5,-46.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-31.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(256)</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"146.5,-23.5 207.5,-23.5 \"/>\r\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(1)</text>\r\n",
       "</g>\r\n",
       "<!-- node3&#45;&gt;node4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>node3&#45;&gt;node4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M115,-106.234C115,-97.7935 115,-88.6188 115,-79.7704\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.5,-79.5964 115,-69.5964 111.5,-79.5964 118.5,-79.5964\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1d159792208>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "g = Digraph('g',node_attr={'shape': 'record', 'height': '.1'})\n",
    "\n",
    "g.node('node0','image')\n",
    "g.node('node1','InceptionV3|{input:|output:}|{(299, 299, 3)|(2048)}')\n",
    "g.node('node2','Dense|{activation:|input:|output:}|{relu|(2048)|(256)}')\n",
    "g.node('node3','Dropout|{dropout_rate:|input:|output:}|{0.2|(256)|(256)}')\n",
    "g.node('node4','Dense|{activation:|input:|output:}|{sigmoid|(256)|(1)}')\n",
    "\n",
    "g.edge('node0','node1')\n",
    "g.edge('node1','node2')\n",
    "g.edge('node2','node3')\n",
    "g.edge('node3','node4')\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基准模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "312/312 [==============================] - 372s - loss: 0.1352 - acc: 0.9483 - val_loss: 0.0526 - val_acc: 0.9804\n",
      "Epoch 2/10\n",
      "312/312 [==============================] - 270s - loss: 0.0696 - acc: 0.9748 - val_loss: 0.0505 - val_acc: 0.9826\n",
      "Epoch 3/10\n",
      "312/312 [==============================] - 269s - loss: 0.0646 - acc: 0.9761 - val_loss: 0.0426 - val_acc: 0.9840\n",
      "Epoch 4/10\n",
      "312/312 [==============================] - 269s - loss: 0.0564 - acc: 0.9786 - val_loss: 0.0489 - val_acc: 0.9830\n",
      "Epoch 5/10\n",
      "312/312 [==============================] - 269s - loss: 0.0554 - acc: 0.9804 - val_loss: 0.0544 - val_acc: 0.9759\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.layers.core import ActivityRegularization\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model1.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model1.input, outputs=predictions)\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model1.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "#model.compile(optimizer=SGD(lr= 0.005, momentum=0.9),\n",
    "#                  loss='binary_crossentropy',\n",
    "#                  metrics=['accuracy']) \n",
    "model.compile(optimizer='adadelta',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy']) \n",
    "# train the model on the new data for a few epochs\n",
    "hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=int(train_file_num*(1-train_valid_split_rate)/BatchSize),\n",
    "        epochs=10,\n",
    "        verbose=1, \n",
    "        callbacks=[earlystopping],\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=int(train_file_num*train_valid_split_rate/BatchSize))\n",
    "model.save_weights('InceptionV3_base.h5')\n",
    "with open('InceptionV3_base.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "with open('InceptionV3_base.txt','w') as f:\n",
    "    f.write(str(hist.history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基准模型预测并提交至kaggle，获得了0.06956的评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995\n",
       "2   3  0.995\n",
       "3   4  0.995\n",
       "4   5  0.005\n",
       "5   6  0.005\n",
       "6   7  0.005\n",
       "7   8  0.005\n",
       "8   9  0.005\n",
       "9  10  0.005"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "test_generator = Img_enerator.flow_from_directory(\n",
    "        'test',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BatchSize,\n",
    "        class_mode='binary',\n",
    "        shuffle = False)\n",
    "with open('InceptionV3_base.json', 'r') as f:\n",
    "    jason_str = f.read()\n",
    "model = model_from_json(jason_str)\n",
    "model.load_weights('InceptionV3_base.h5')\n",
    "test = model.predict_generator(test_generator,len(test_generator.filenames)/BatchSize )\n",
    "y_pred = test.clip(min=0.005, max=0.995)\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "# 获取文件的序号并减1，然后设置到新预测的csv文件的序号\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int((fname.split('\\\\')[1]).split('.')[0])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "df.to_csv('InceptionV3_base_sub.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试不同模型并训练部分卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试Inception模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "312/312 [==============================] - 314s - loss: 0.1796 - acc: 0.9583 - val_loss: 0.0656 - val_acc: 0.9894\n",
      "Epoch 2/10\n",
      "312/312 [==============================] - 305s - loss: 0.0416 - acc: 0.9983 - val_loss: 0.0440 - val_acc: 0.9887\n",
      "Epoch 3/10\n",
      "312/312 [==============================] - 305s - loss: 0.0270 - acc: 0.9987 - val_loss: 0.0351 - val_acc: 0.9895\n",
      "Epoch 4/10\n",
      "312/312 [==============================] - 306s - loss: 0.0205 - acc: 0.9987 - val_loss: 0.0309 - val_acc: 0.9897\n",
      "Epoch 5/10\n",
      "312/312 [==============================] - 307s - loss: 0.0156 - acc: 0.9990 - val_loss: 0.0283 - val_acc: 0.9901\n",
      "Epoch 6/10\n",
      "312/312 [==============================] - 304s - loss: 0.0146 - acc: 0.9985 - val_loss: 0.0289 - val_acc: 0.9899\n",
      "Epoch 7/10\n",
      "312/312 [==============================] - 306s - loss: 0.0123 - acc: 0.9988 - val_loss: 0.0275 - val_acc: 0.9895\n",
      "Epoch 8/10\n",
      "312/312 [==============================] - 305s - loss: 0.0113 - acc: 0.9989 - val_loss: 0.0274 - val_acc: 0.9901\n",
      "Epoch 9/10\n",
      "312/312 [==============================] - 306s - loss: 0.0103 - acc: 0.9992 - val_loss: 0.0262 - val_acc: 0.9901\n",
      "Epoch 10/10\n",
      "312/312 [==============================] - 305s - loss: 0.0093 - acc: 0.9990 - val_loss: 0.0260 - val_acc: 0.9903\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model1.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model1.input, outputs=predictions)\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model1.layers[:250]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model1.layers[250:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "Img_enerator = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = Img_enerator.flow_from_directory(\n",
    "        'train2',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BatchSize,\n",
    "        class_mode='binary')\n",
    "validation_generator = Img_enerator.flow_from_directory(\n",
    "        'validation',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BatchSize,\n",
    "        class_mode='binary')\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "#model.compile(optimizer=RMSprop(lr= 0.0045), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.compile(optimizer=SGD(lr=0.0001,momentum=0.9),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy']) \n",
    "Img_enerator = ImageDataGenerator()\n",
    "# train the model on the new data for a few epochs\n",
    "hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=int(train_file_num*(1-train_valid_split_rate)/BatchSize),\n",
    "        epochs=10,\n",
    "        verbose=1, \n",
    "        callbacks=[earlystopping],\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=int(train_file_num*train_valid_split_rate/BatchSize))\n",
    "model.save_weights('InceptionV3_finetune.h5')\n",
    "with open('InceptionV3_finetune.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "with open('log_InceptionV3_finetune.txt','w') as f:\n",
    "    f.write(str(hist.history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试ResNet50模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "312/312 [==============================] - 263s - loss: 0.2520 - acc: 0.8979 - val_loss: 0.0875 - val_acc: 0.9718\n",
      "Epoch 2/10\n",
      "312/312 [==============================] - 254s - loss: 0.0934 - acc: 0.9674 - val_loss: 0.0636 - val_acc: 0.9789\n",
      "Epoch 3/10\n",
      "312/312 [==============================] - 254s - loss: 0.0683 - acc: 0.9762 - val_loss: 0.0553 - val_acc: 0.9793\n",
      "Epoch 4/10\n",
      "312/312 [==============================] - 255s - loss: 0.0577 - acc: 0.9790 - val_loss: 0.0457 - val_acc: 0.9836\n",
      "Epoch 5/10\n",
      "312/312 [==============================] - 256s - loss: 0.0504 - acc: 0.9822 - val_loss: 0.0450 - val_acc: 0.9816\n",
      "Epoch 6/10\n",
      "312/312 [==============================] - 257s - loss: 0.0432 - acc: 0.9838 - val_loss: 0.0408 - val_acc: 0.9848\n",
      "Epoch 7/10\n",
      "312/312 [==============================] - 255s - loss: 0.0416 - acc: 0.9847 - val_loss: 0.0439 - val_acc: 0.9822\n",
      "Epoch 8/10\n",
      "312/312 [==============================] - 253s - loss: 0.0360 - acc: 0.9868 - val_loss: 0.0362 - val_acc: 0.9854\n",
      "Epoch 9/10\n",
      "312/312 [==============================] - 256s - loss: 0.0311 - acc: 0.9891 - val_loss: 0.0374 - val_acc: 0.9848\n",
      "Epoch 10/10\n",
      "312/312 [==============================] - 249s - loss: 0.0257 - acc: 0.9912 - val_loss: 0.0395 - val_acc: 0.9834\n"
     ]
    }
   ],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model2.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model2.input, outputs=predictions)\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model2.layers[:124]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model2.layers[124:]:\n",
    "    layer.trainable = True\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "#model.compile(optimizer=RMSprop(lr= 0.0045), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.compile(optimizer=SGD(lr=0.0002,momentum=0.9),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy']) \n",
    "Img_enerator = ImageDataGenerator()\n",
    "train_generator = Img_enerator.flow_from_directory(\n",
    "        'train2',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=BatchSize,\n",
    "        class_mode='binary')\n",
    "validation_generator = Img_enerator.flow_from_directory(\n",
    "        'validation',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=BatchSize,\n",
    "        class_mode='binary')\n",
    "# train the model on the new data for a few epochs\n",
    "hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=int(train_file_num*(1-train_valid_split_rate)/BatchSize),\n",
    "        epochs=10,\n",
    "        verbose=1, \n",
    "        callbacks=[earlystopping],\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=int(train_file_num*train_valid_split_rate/BatchSize))\n",
    "model.save_weights('ResNet50_finetune.h5')\n",
    "with open('ResNet50_finetun.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "with open('log_ResNet50_finetune.txt','w') as f:\n",
    "    f.write(str(hist.history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试Xception模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "312/312 [==============================] - 494s - loss: 0.1960 - acc: 0.9696 - val_loss: 0.0656 - val_acc: 0.9896\n",
      "Epoch 2/10\n",
      "312/312 [==============================] - 483s - loss: 0.0582 - acc: 0.9879 - val_loss: 0.0381 - val_acc: 0.9917\n",
      "Epoch 3/10\n",
      "312/312 [==============================] - 483s - loss: 0.0418 - acc: 0.9891 - val_loss: 0.0325 - val_acc: 0.9911\n",
      "Epoch 4/10\n",
      "312/312 [==============================] - 483s - loss: 0.0357 - acc: 0.9890 - val_loss: 0.0291 - val_acc: 0.9917\n",
      "Epoch 5/10\n",
      "312/312 [==============================] - 486s - loss: 0.0319 - acc: 0.9893 - val_loss: 0.0244 - val_acc: 0.9931\n",
      "Epoch 6/10\n",
      "312/312 [==============================] - 482s - loss: 0.0300 - acc: 0.9901 - val_loss: 0.0219 - val_acc: 0.9931\n",
      "Epoch 7/10\n",
      "312/312 [==============================] - 485s - loss: 0.0279 - acc: 0.9908 - val_loss: 0.0195 - val_acc: 0.9935\n",
      "Epoch 8/10\n",
      "312/312 [==============================] - 485s - loss: 0.0263 - acc: 0.9913 - val_loss: 0.0218 - val_acc: 0.9933\n",
      "Epoch 9/10\n",
      "312/312 [==============================] - 485s - loss: 0.0239 - acc: 0.9922 - val_loss: 0.0205 - val_acc: 0.9933\n"
     ]
    }
   ],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model3.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=base_model3.input, outputs=predictions)\n",
    "for layer in base_model3.layers[:82]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model3.layers[82:]:\n",
    "    layer.trainable = True\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "#model.compile(optimizer=RMSprop(lr= 0.0045), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.compile(optimizer=SGD(lr=0.0003,momentum=0.9),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy']) \n",
    "Img_enerator = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = Img_enerator.flow_from_directory(\n",
    "        'train2',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BatchSize,\n",
    "        class_mode='binary')\n",
    "validation_generator = Img_enerator.flow_from_directory(\n",
    "        'validation',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BatchSize,\n",
    "        class_mode='binary')\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=int(train_file_num*(1-train_valid_split_rate)/BatchSize),\n",
    "        epochs=10,\n",
    "        verbose=1, \n",
    "        callbacks=[earlystopping],\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=int(train_file_num*train_valid_split_rate/BatchSize))\n",
    "model.save_weights('Xception_finetune.h5')\n",
    "with open('Xception_finetune.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "with open('log_Xception0_finetune.txt','w') as f:\n",
    "    f.write(str(hist.history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2)从上述三个模型的val_loss来看，Xception的loss结果较优，所以选取Xception进行dropout参数调优\n",
    "## 从下述运行结果可以看出在0.4的时候模型val_loss较低，也比较稳定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "312/312 [==============================] - 493s - loss: 0.3305 - acc: 0.9068 - val_loss: 0.1219 - val_acc: 0.9870\n",
      "Epoch 2/15\n",
      "312/312 [==============================] - 487s - loss: 0.1076 - acc: 0.9811 - val_loss: 0.0588 - val_acc: 0.9895\n",
      "Epoch 3/15\n",
      "312/312 [==============================] - 489s - loss: 0.0667 - acc: 0.9846 - val_loss: 0.0379 - val_acc: 0.9915\n",
      "Epoch 4/15\n",
      "312/312 [==============================] - 489s - loss: 0.0518 - acc: 0.9867 - val_loss: 0.0330 - val_acc: 0.9915\n",
      "Epoch 5/15\n",
      "312/312 [==============================] - 489s - loss: 0.0449 - acc: 0.9881 - val_loss: 0.0295 - val_acc: 0.9917\n",
      "Epoch 6/15\n",
      "312/312 [==============================] - 490s - loss: 0.0406 - acc: 0.9875 - val_loss: 0.0225 - val_acc: 0.9937\n",
      "Epoch 7/15\n",
      "312/312 [==============================] - 490s - loss: 0.0377 - acc: 0.9884 - val_loss: 0.0261 - val_acc: 0.9915\n",
      "Epoch 8/15\n",
      "312/312 [==============================] - 481s - loss: 0.0328 - acc: 0.9897 - val_loss: 0.0229 - val_acc: 0.9927\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "312/312 [==============================] - 484s - loss: 0.2157 - acc: 0.9531 - val_loss: 0.0643 - val_acc: 0.9898\n",
      "Epoch 2/15\n",
      "312/312 [==============================] - 482s - loss: 0.0624 - acc: 0.9869 - val_loss: 0.0373 - val_acc: 0.9911\n",
      "Epoch 3/15\n",
      "312/312 [==============================] - 482s - loss: 0.0453 - acc: 0.9883 - val_loss: 0.0290 - val_acc: 0.9929\n",
      "Epoch 4/15\n",
      "312/312 [==============================] - 482s - loss: 0.0369 - acc: 0.9896 - val_loss: 0.0220 - val_acc: 0.9937\n",
      "Epoch 5/15\n",
      "312/312 [==============================] - 484s - loss: 0.0325 - acc: 0.9904 - val_loss: 0.0233 - val_acc: 0.9929\n",
      "Epoch 6/15\n",
      "312/312 [==============================] - 486s - loss: 0.0300 - acc: 0.9907 - val_loss: 0.0187 - val_acc: 0.9953\n",
      "Epoch 7/15\n",
      "312/312 [==============================] - 484s - loss: 0.0264 - acc: 0.9914 - val_loss: 0.0222 - val_acc: 0.9923\n",
      "Epoch 8/15\n",
      "312/312 [==============================] - 486s - loss: 0.0262 - acc: 0.9913 - val_loss: 0.0183 - val_acc: 0.9933\n",
      "Epoch 9/15\n",
      "312/312 [==============================] - 486s - loss: 0.0241 - acc: 0.9919 - val_loss: 0.0181 - val_acc: 0.9941\n",
      "Epoch 10/15\n",
      "312/312 [==============================] - 485s - loss: 0.0240 - acc: 0.9921 - val_loss: 0.0183 - val_acc: 0.9937\n",
      "Epoch 11/15\n",
      "312/312 [==============================] - 485s - loss: 0.0226 - acc: 0.9927 - val_loss: 0.0176 - val_acc: 0.9935\n",
      "Epoch 12/15\n",
      "312/312 [==============================] - 483s - loss: 0.0223 - acc: 0.9919 - val_loss: 0.0182 - val_acc: 0.9933\n",
      "Epoch 13/15\n",
      "312/312 [==============================] - 483s - loss: 0.0204 - acc: 0.9935 - val_loss: 0.0190 - val_acc: 0.9929\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "312/312 [==============================] - 492s - loss: 0.1604 - acc: 0.9766 - val_loss: 0.0492 - val_acc: 0.9922\n",
      "Epoch 2/15\n",
      "312/312 [==============================] - 484s - loss: 0.0440 - acc: 0.9920 - val_loss: 0.0288 - val_acc: 0.9935\n",
      "Epoch 3/15\n",
      "312/312 [==============================] - 482s - loss: 0.0322 - acc: 0.9925 - val_loss: 0.0259 - val_acc: 0.9925\n",
      "Epoch 4/15\n",
      "312/312 [==============================] - 486s - loss: 0.0262 - acc: 0.9925 - val_loss: 0.0212 - val_acc: 0.9933\n",
      "Epoch 5/15\n",
      "312/312 [==============================] - 487s - loss: 0.0235 - acc: 0.9926 - val_loss: 0.0202 - val_acc: 0.9931\n",
      "Epoch 6/15\n",
      "312/312 [==============================] - 483s - loss: 0.0223 - acc: 0.9934 - val_loss: 0.0240 - val_acc: 0.9907\n",
      "Epoch 7/15\n",
      "312/312 [==============================] - 487s - loss: 0.0215 - acc: 0.9929 - val_loss: 0.0186 - val_acc: 0.9933\n",
      "Epoch 8/15\n",
      "312/312 [==============================] - 484s - loss: 0.0190 - acc: 0.9939 - val_loss: 0.0178 - val_acc: 0.9933\n",
      "Epoch 9/15\n",
      "312/312 [==============================] - 486s - loss: 0.0187 - acc: 0.9934 - val_loss: 0.0178 - val_acc: 0.9927\n",
      "Epoch 10/15\n",
      "312/312 [==============================] - 484s - loss: 0.0164 - acc: 0.9949 - val_loss: 0.0184 - val_acc: 0.9921\n",
      "Epoch 11/15\n",
      "312/312 [==============================] - 486s - loss: 0.0171 - acc: 0.9947 - val_loss: 0.0182 - val_acc: 0.9923\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "312/312 [==============================] - 493s - loss: 0.1426 - acc: 0.9736 - val_loss: 0.0402 - val_acc: 0.9920\n",
      "Epoch 2/15\n",
      "312/312 [==============================] - 488s - loss: 0.0338 - acc: 0.9938 - val_loss: 0.0263 - val_acc: 0.9917\n",
      "Epoch 3/15\n",
      "312/312 [==============================] - 487s - loss: 0.0249 - acc: 0.9937 - val_loss: 0.0214 - val_acc: 0.9935\n",
      "Epoch 4/15\n",
      "312/312 [==============================] - 485s - loss: 0.0214 - acc: 0.9937 - val_loss: 0.0223 - val_acc: 0.9917\n",
      "Epoch 5/15\n",
      "312/312 [==============================] - 487s - loss: 0.0178 - acc: 0.9949 - val_loss: 0.0179 - val_acc: 0.9935\n",
      "Epoch 6/15\n",
      "312/312 [==============================] - 483s - loss: 0.0166 - acc: 0.9951 - val_loss: 0.0182 - val_acc: 0.9929\n",
      "Epoch 7/15\n",
      "312/312 [==============================] - 485s - loss: 0.0164 - acc: 0.9945 - val_loss: 0.0193 - val_acc: 0.9911\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "312/312 [==============================] - 490s - loss: 0.1357 - acc: 0.9767 - val_loss: 0.0374 - val_acc: 0.9934\n",
      "Epoch 2/15\n",
      "312/312 [==============================] - 488s - loss: 0.0291 - acc: 0.9953 - val_loss: 0.0245 - val_acc: 0.9937\n",
      "Epoch 3/15\n",
      "312/312 [==============================] - 484s - loss: 0.0220 - acc: 0.9949 - val_loss: 0.0201 - val_acc: 0.9943\n",
      "Epoch 4/15\n",
      "312/312 [==============================] - 487s - loss: 0.0177 - acc: 0.9950 - val_loss: 0.0181 - val_acc: 0.9937\n",
      "Epoch 5/15\n",
      "312/312 [==============================] - 486s - loss: 0.0181 - acc: 0.9947 - val_loss: 0.0169 - val_acc: 0.9945\n",
      "Epoch 6/15\n",
      "312/312 [==============================] - 487s - loss: 0.0148 - acc: 0.9956 - val_loss: 0.0200 - val_acc: 0.9929\n",
      "Epoch 7/15\n",
      "312/312 [==============================] - 483s - loss: 0.0143 - acc: 0.9958 - val_loss: 0.0161 - val_acc: 0.9945\n",
      "Epoch 8/15\n",
      "312/312 [==============================] - 488s - loss: 0.0139 - acc: 0.9956 - val_loss: 0.0198 - val_acc: 0.9929\n",
      "Epoch 9/15\n",
      "312/312 [==============================] - 487s - loss: 0.0125 - acc: 0.9956 - val_loss: 0.0162 - val_acc: 0.9939\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "312/312 [==============================] - 496s - loss: 0.1191 - acc: 0.9747 - val_loss: 0.0346 - val_acc: 0.9932\n",
      "Epoch 2/15\n",
      "312/312 [==============================] - 487s - loss: 0.0249 - acc: 0.9962 - val_loss: 0.0240 - val_acc: 0.9935\n",
      "Epoch 3/15\n",
      "312/312 [==============================] - 487s - loss: 0.0184 - acc: 0.9959 - val_loss: 0.0206 - val_acc: 0.9935\n",
      "Epoch 4/15\n",
      "312/312 [==============================] - 485s - loss: 0.0155 - acc: 0.9961 - val_loss: 0.0204 - val_acc: 0.9935\n",
      "Epoch 5/15\n",
      "312/312 [==============================] - 487s - loss: 0.0135 - acc: 0.9963 - val_loss: 0.0193 - val_acc: 0.9927\n",
      "Epoch 6/15\n",
      "312/312 [==============================] - 486s - loss: 0.0126 - acc: 0.9966 - val_loss: 0.0202 - val_acc: 0.9929\n",
      "Epoch 7/15\n",
      "312/312 [==============================] - 488s - loss: 0.0121 - acc: 0.9970 - val_loss: 0.0145 - val_acc: 0.9947\n",
      "Epoch 8/15\n",
      "312/312 [==============================] - 488s - loss: 0.0128 - acc: 0.9960 - val_loss: 0.0153 - val_acc: 0.9949\n",
      "Epoch 9/15\n",
      "312/312 [==============================] - 487s - loss: 0.0107 - acc: 0.9968 - val_loss: 0.0168 - val_acc: 0.9939\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "drop_rate_matrix = np.linspace(0.6, 0.1, 6)\n",
    "for i,drop_rate in enumerate(drop_rate_matrix):\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model3.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(drop_rate)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model3.input, outputs=predictions)\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model3.layers[:82]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model3.layers[82:]:\n",
    "        layer.trainable = True\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    #model.compile(optimizer=RMSprop(lr= 0.0045), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    model.compile(optimizer=SGD(lr=0.0003,momentum=0.9),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy']) \n",
    "    Img_enerator = ImageDataGenerator(rescale=1./255)\n",
    "    train_generator = Img_enerator.flow_from_directory(\n",
    "            'train2',\n",
    "            target_size=(299, 299),\n",
    "            batch_size=BatchSize,\n",
    "            class_mode='binary')\n",
    "    validation_generator = Img_enerator.flow_from_directory(\n",
    "            'validation',\n",
    "            target_size=(299, 299),\n",
    "            batch_size=BatchSize,\n",
    "            class_mode='binary')\n",
    "\n",
    "    # train the model on the new data for a few epochs\n",
    "    hist = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=int(train_file_num*(1-train_valid_split_rate)/BatchSize),\n",
    "            epochs=15,\n",
    "            verbose=1, \n",
    "            callbacks=[earlystopping],\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=int(train_file_num*train_valid_split_rate/BatchSize))\n",
    "    model.save_weights('Xception_droprate_%s.h5'%drop_rate_matrix[i])\n",
    "    with open('Xception_droprate_%s.json'%drop_rate_matrix[i], 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "    with open('log_Xception_droprate_%s.txt'%drop_rate_matrix[i],'w') as f:\n",
    "        f.write(str(hist.history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 首先，我根据最好的模型Xception_droprate_0.2 model画出其val_loss曲线图，然后做出预测，并写入csv文件，然后提交至kaggle，获得了0.4163的评分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAGHCAYAAABxmBIgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d1c549bb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "with open('log_Xception_droprate_0.2.txt', 'r') as f:\n",
    "    log_str = f.read()\n",
    "log_str = eval(log_str)\n",
    "log_val_loss = log_str['val_loss']\n",
    "log_epoch = np.linspace(1,len(log_val_loss),len(log_val_loss))\n",
    "plt.plot(log_epoch, log_val_loss)\n",
    "plt.title('Xception_droprate_0.2 model val_loss figure')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.ylabel('val_loss') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "with open('Xception_droprate_0.2.json', 'r') as f:\n",
    "    jason_str = f.read()\n",
    "model = model_from_json(jason_str)\n",
    "model.load_weights('Xception_droprate_0.2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "Img_enerator = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = Img_enerator.flow_from_directory(\n",
    "        'test',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=BatchSize,\n",
    "        class_mode='binary',\n",
    "        shuffle = False)\n",
    "test = model.predict_generator(test_generator,len(test_generator.filenames)/BatchSize )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995\n",
       "2   3  0.995\n",
       "3   4  0.995\n",
       "4   5  0.005\n",
       "5   6  0.005\n",
       "6   7  0.005\n",
       "7   8  0.005\n",
       "8   9  0.005\n",
       "9  10  0.005"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = test.clip(min=0.005, max=0.995)\n",
    "\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "# 获取文件的序号并减1，然后设置到新预测的csv文件的序号\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int((fname.split('\\\\')[1]).split('.')[0])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('Xception_droprate_0.2_sub.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
